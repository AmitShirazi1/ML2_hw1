{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "yRxF3fGk83TKVLrMatsfF6",
     "type": "MD"
    }
   },
   "source": [
    "# <u>Submission instructions</u>\n",
    "### Submission in pairs unless otherwise authorized\n",
    "<ul style=\"font-size: 17px\">\n",
    "<li> This notebook contains all the questions. You should follow the instructions below.</li>\n",
    "<li> Solutions for both theoretical and practical parts should be written in this notebook</li>\n",
    "</ul>\n",
    "\n",
    "<h3> Moodle submission</h3>\n",
    "\n",
    "\n",
    "<p style=\"font-size: 17px\">\n",
    "You should submit three files:\n",
    "</p>\n",
    "<ul style=\"font-size: 17px\">\n",
    "<li>IPYNB notebook:\n",
    "  <ul>\n",
    "  <li>All the wet and dry parts, including code, graphs, discussion, etc.</li>\n",
    "  </ul>\n",
    "</li>\n",
    "<li>PDF file:\n",
    "  <ul>\n",
    "  <li>Export the notebook to PDF. Make sure that all the cells are visible.</li>\n",
    "  </ul>\n",
    "</li>\n",
    "<li>Pickle files:\n",
    "  <ul>\n",
    "    <li>As requested in Q2.a and Q3.a</li>\n",
    "  </ul>\n",
    "</li>\n",
    "<li> PY file:\n",
    "  <ul>\n",
    "   <li> As requested in Q3.a</li>\n",
    "   </ul>\n",
    "   </li>\n",
    "</ul>\n",
    "<p style=\"font-size: 17px\">\n",
    "All files should be in the following format: \"HW1_ID1_ID2.file\"\n",
    "<br>\n",
    "Good Luck!\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "mYiXOlyvoIiYs0VuDro4xC",
     "type": "MD"
    }
   },
   "source": [
    "<h1> Question 1</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "soZCVUP0PzcQexv4G9bDRg",
     "type": "MD"
    }
   },
   "source": [
    "## I. Softmax Derivative (10pt)\n",
    "\n",
    "<p style=\"font-size: 17px\">\n",
    "Derive the gradients of the softmax function and demonstrate how the expression can be reformulated solely by using the softmax function, i.e., in some expression where only $softmax(x)$, but not $x$, is present). Recall that the softmax function is defined as follows:\n",
    "\n",
    "$$softmax(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{N} e^{x_j}}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "IpqCRRTyHjo6KCJA6LIqmx",
     "type": "MD"
    }
   },
   "source": [
    "### I. Softmax Derivative - Answer:\n",
    "$$ \\frac{\\partial softmax(x)_i}{\\partial x_k} = \\frac{\\partial }{\\partial x_k} (\\frac{e^{x_i}}{\\sum_{j=1}^{N} e^{x_j}})= $$\n",
    "$$ = (\\frac{\\partial }{\\partial x_k} e^{x_i}) \\cdot \\frac{1}{\\sum_{j=1}^{N} e^{x_j}} + e^{x_i}(\\frac{\\partial }{\\partial x_k} \\frac{1}{\\sum_{j=1}^{N} e^{x_j}})= $$\n",
    "$$ = \\frac{e^{x_k}}{\\sum_{j=1}^{N} e^{x_j}} \\cdot I_{i=k} - \\frac{e^{x_i}e^{x_k}}{(\\sum_{j=1}^{N} e^{x_j})^2}= $$\n",
    "$$ = \\frac{e^{x_k}}{\\sum_{j=1}^{N} e^{x_j}} \\cdot I_{i=k} - \\frac{e^{x_i}}{\\sum_{j=1}^{N} e^{x_j}} \\cdot \\frac{e^{x_k}}{\\sum_{j=1}^{N} e^{x_j}}= $$\n",
    "$$ = softmax(x)_k \\cdot I_{i=k} - softmax(x)_i \\cdot softmax(x)_k= $$\n",
    "$$ = softmax(x)_k (I_{i=k} - softmax(x)_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Cross-Entropy Gradient (10pt)\n",
    "<p style=\"font-size: 17px\">\n",
    "Derive the gradient of cross-entropy loss with regard to the inputs of a softmax function. i.e., find the gradients with respect to the softmax input vector $\\theta$, when the prediction is denoted by $\\hat{y} = softmax(\\theta)$. Remember the cross entropy function is:\n",
    "$$CE(y, \\hat{y}) = -\\sum_i y_i log(\\hat{y_i})$$\n",
    "\n",
    "\n",
    "<p style=\"font-size: 17px\">where $y$ is the one-hot label vector, and $\\hat{y}$ is the predicted probability vector for all classes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "qm487O2HSrGtnaEuKf0Yet",
     "type": "MD"
    }
   },
   "source": [
    "### II. Cross-Entropy Gradient - Answer\n",
    "\n",
    "<!--- write your answer -->\n",
    "$$\\frac{\\partial CE(y, \\hat{y})}{\\partial\\theta} = ( \\frac{\\partial CE(y, \\hat{y})}{\\partial\\theta _1} , \\frac{\\partial CE(y, \\hat{y})}{\\partial\\theta _2} , ... , \\frac{\\partial CE(y, \\hat{y})}{\\partial\\theta _N} ) $$\n",
    "$$ \\Downarrow $$\n",
    "$$ \\frac{\\partial CE(y, \\hat{y})}{\\partial\\theta _k} = \\frac{\\partial CE(y, \\hat{y})}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial\\theta _k} = $$\n",
    "$$ \\sum_{i=1}^{N} \\frac{\\partial CE(y, \\hat{y})}{\\partial \\hat{y}_i} \\cdot \\frac{\\partial \\hat{y}_i}{\\partial\\theta _k} = $$\n",
    "$$ \\sum_{i=1}^{N} (- \\frac{y_i}{\\hat{y}_i} \\cdot \\hat{y}_k (I_{i=k} - \\hat{y}_i) ) = $$\n",
    "$$ \\sum_{i=1}^{N} (- y_i I_{i=k} + y_i \\hat{y}_k ) = $$\n",
    "$$ - y_k + (\\sum_{i=1}^{N} y_i) \\hat{y}_k = $$\n",
    "$$ - y_k + 1 \\cdot \\hat{y}_k = \\hat{y}_k - y_k $$\n",
    "$$ \\Downarrow $$\n",
    "$$\\frac{\\partial CE(y, \\hat{y})}{\\partial\\theta} = ( \\hat{y}_1 - y_1 , \\hat{y}_2 - y_2 , ... , \\hat{y}_N - y_N )$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "XXTewYlH5FSAKliEp1LYVr",
     "type": "MD"
    }
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "eU1spAtEoWOmiuz8b1epc6",
     "type": "MD"
    }
   },
   "source": [
    "## I. Derivative Of Activation Functions (10pt)\n",
    "\n",
    "<p style=\"font-size: 17px\">\n",
    "The following cell contains an implementation of some activation functions. Implement the corresponding derivatives.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "KnegWR2iltc4XwyJw0Fdw3",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return torch.div(torch.exp(x) - torch.exp(-x), torch.exp(x) + torch.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = torch.exp(x.T - torch.max(x, dim=-1).values).T  # Subtracting max(x) for numerical stability\n",
    "    return exp_x / exp_x.sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "maCkjVZ0dIFKS1IPadow46",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def d_sigmoid(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "def d_tanh(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "def d_softmax(x):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "GaitupBIkrSaDCvQc5buP5",
     "type": "MD"
    }
   },
   "source": [
    "## II. Train a Fully Connected network on MNIST (30pt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "An2t0OVJDND2S2KElPOtHf",
     "type": "MD"
    }
   },
   "source": [
    "<p style=\"font-size: 17px\">In the following exercise, you will create a classifier for the MNIST dataset.\n",
    "You should write your own training and evaluation code and meet the following\n",
    "constraints:\n",
    "<ul>\n",
    "<li> You are only allowed to use torch tensor manipulations.</li>\n",
    "<li> You are NOT allowed to use:\n",
    "  <ul>\n",
    "  <li> Auto-differentiation - backward()</li>\n",
    "  <li> Built-in loss functions</li>\n",
    "  <li> Built-in activations</li>\n",
    "  <li> Built-in optimization</li>\n",
    "  <li> Built-in layers (torch.nn)</li>\n",
    "  </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "</h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "RJnSAOesGYsgF2m9BMUfzK",
     "type": "MD"
    }
   },
   "source": [
    "<p style=\"font-size: 17px\">\n",
    " a) The required classifier class is defined.\n",
    "<ul style=\"font-size: 17px\">\n",
    "<li> You should implement the forward and backward passes of the model.\n",
    "<li> Train the model and plot the model's accuracy and loss (both on train and test sets) as a function of the epochs.\n",
    "<li> You should save the model's weights and biases. Change the student_ids to yours.\n",
    "</ul>\n",
    "<p style=\"font-size: 17px\">In this section, you <b>must</b> use the \"set_seed\" function with the given seed and <b>sigmoid</b> as an activation function.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "aJySKnlSpLwCl0eoJYCaFN",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "# Constants\n",
    "SEED = 42\n",
    "EPOCHS = 16\n",
    "BATCH_SIZE = 32\n",
    "NUM_OF_CLASSES = 10\n",
    "\n",
    "# Setting seed\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "# Transformation for the data\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torch.flatten])\n",
    "\n",
    "\n",
    "# Cross-Entropy loss implementation\n",
    "def one_hot(y, num_of_classes=10):\n",
    "    hot = torch.zeros((y.size()[0], num_of_classes))\n",
    "    hot[torch.arange(y.size()[0]), y] = 1\n",
    "    return hot\n",
    "\n",
    "def cross_entropy(y, y_hat):\n",
    "    return -torch.sum(one_hot(y) * torch.log(y_hat)) / y.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "lo57lFKyOqQmMGfLR0Meso",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "nuoAPQXRzhYGwelAr4CeWe",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class FullyConnectedNetwork:\n",
    "    def __init__(self, input_size, output_size, hidden_size1, activiation_func, lr=0.01):\n",
    "        # parameters\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "\n",
    "        # activation function\n",
    "        self.activation_func = activiation_func\n",
    "\n",
    "        # weights\n",
    "        self.W1 = torch.randn(self.input_size, self.hidden_size1)\n",
    "        self.b1 = torch.zeros(self.hidden_size1)\n",
    "\n",
    "        self.W2 = torch.randn(self.hidden_size1, self.output_size)\n",
    "        self.b2 = torch.zeros(self.output_size)\n",
    "\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def backward(self, x, y, y_hat):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "9KzKsJARUjbine4dVjkfg2",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "model = FullyConnectedNetwork(784, 10, 128, sigmoid, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Mb57Mq1FFlv4rrr7hinJlz",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Write a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "oNEyQXyvcWyjxSQwcivnEJ",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "students_ids = \"12345789_987654321\"\n",
    "torch.save({\"W1\": model.W1, \"W2\": model.W2, \"b1\": model.b1, \"b2\": model.b2}, f\"HW1_{students_ids}.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "bLjHSOjQThjOLvJ8hOgvr6",
     "type": "MD"
    }
   },
   "source": [
    "<p style=\"font-size: 17px\"> b) Train the model with various learning rates (at least 3).\n",
    "<ul style=\"font-size: 17px\">\n",
    "<li> Plot the model's accuracy and loss (both on train and test sets) as a function of the epochs.\n",
    "<li>Discuss the differences in training with different learning rates. Support your answer with plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "dn5x92wZhavymdcmZMKJ7u",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "8qd1yAbzAT1xIRQtWUUHoY",
     "type": "MD"
    }
   },
   "source": [
    "# Question 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "WC7InslhxyIvCc38ESrBDr",
     "type": "MD"
    }
   },
   "source": [
    "## I. Implement and Train a CNN (30pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 17px\"> As you might know, there are many dogs on campus. Sometimes, understanding the emotions of a dog can be challenging, and people might mistakenly try to pet it when it is sad or angry. As a data scientist, you have been asked to assist Technion's students. Your task is to create a \"dog emotion classifier.\n",
    "<br>\n",
    "Your code should meet the following constraints:\n",
    "<ul style=\"font-size: 17px\">\n",
    "<li> Your classifier must be CNN based</li>\n",
    "<li> You are not allowed to use any pre-trained model</li>\n",
    "</ul>\n",
    "<br>\n",
    "<p style=\"font-size: 17px\">\n",
    "To satisfy your boss, your model must achieve at least 70% accuracy on the test set. Your boss also emphasized that the model will be deployed on smartphones, so it should have a small number of parameters. 25% of your grade for this task will be based on the number of parameters your model uses â€” fewer parameters will yield a higher grade.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stages\n",
    "<ol style=\"font-size: 17px\"> \n",
    "<li>Perform a short EDA (Exploratory Data Analysis).</li>\n",
    " <li>Train the model and plot its accuracy and loss (for both the training and validation sets) as a function of the epochs.</li>\n",
    "  <li>Report the test set accuracy.</li>\n",
    "   <li>Discuss the progress you made and describe your final model.</li>\n",
    "    </ol>\n",
    "<br>\n",
    " Your data is in <code>hw1_data/dog_emotion</code>.\n",
    "<br>\n",
    "Tou can define a custom dataset (as in tutorial 3) or use <code>torchvision.datasets.ImageFolder</code>.\n",
    "\n",
    " #### Submission\n",
    " <p style=\"font-size: 17px\"> In addition to the code in the notebook, you should submit:\n",
    "<ul style=\"font-size: 17px\">\n",
    "<li> a <code>.py</code> file containing your model class.</li>\n",
    "<li> a <code>.pkl</code> file containing the weight of your model</li>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ITjBAln5fGCruMZYHgjF35",
     "type": "MD"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "vSn3WoVprpB4oQzf2wu5sH",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Fq3Hl4TmKAzC5Xw1b7iBpZ",
     "type": "MD"
    }
   },
   "source": [
    "## II. Analyzing a Pre-trained CNN (Filters) (10pt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "1KKmAN8YX0fDzOJct7vTn4",
     "type": "MD"
    }
   },
   "source": [
    "In this part, you are going to analyze a (large) pre-trained model. Pre-trained models are quite popular these days, as big companies can train really large models on large datasets (something that personal users can't do as they lack the sufficient hardware). These pre-trained models can be used to fine-tune on other/small datasets or used as components in other tasks (like using a pre-trained classifier for object detection).\n",
    "\n",
    "All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n",
    "\n",
    "You can use the following transform to normalize:\n",
    "\n",
    "<code>normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])</code>\n",
    "<a href=\"https://pytorch.org/vision/stable/models.html\">Read more here</a>\n",
    "\n",
    "\n",
    "1. Load a pre-trained VGG16 with PyTorch using torchvision.models.vgg16(pretrained=True, progress=True, **kwargs) (<a href=\"https://pytorch.org/vision/stable/models.html#classification\">read more here</a>). Don't forget to use the model in evaluation mode (<code>model.eval()</code>).\n",
    "\n",
    "2. Load the images in the <code>hw1_data/birds</code> folder and display them.\n",
    "\n",
    "3. Pre-process the images to fit VGG16's architecture. What steps did you take?\n",
    "\n",
    "4. Feed the images (forward pass) to the model. What are the outputs?\n",
    "\n",
    "5. Choose an image of a dog in the <code>hw1_data/dogs</code> folder, display it and feed it to network. What are the outputs?\n",
    "\n",
    "6. For the first 3 filters in the first layer of VGG16, plot their response (their output) for the image from section 5. Explain what do you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "0BzbPyE0k11Lv0oAVY4as0",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
